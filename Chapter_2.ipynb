{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'DenseNet',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'MNASNet',\n",
       " 'MobileNetV2',\n",
       " 'ResNet',\n",
       " 'ShuffleNetV2',\n",
       " 'SqueezeNet',\n",
       " 'VGG',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'quantization',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'utils',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet101(pretrained=False)\n",
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.load_state_dict(torch.load(\"resnet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# sort of like putting layers of transformations together\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(254),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"dog.jpeg\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 254, 254])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_p = preprocess(img)\n",
    "img_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 254, 254])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_r = torch.unsqueeze(img_p, 0)\n",
    "img_r.shape\n",
    "# 1 dimension added at beginning to refer to the number of examples in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.eval() # important for the model to predict properly\n",
    "# eval basically tells the model that some layers such as dropout\n",
    "# and batchnorm are not to be used while evaluating\n",
    "out = resnet(img_r)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data_labels.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(208)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, idx = torch.max(out, 1)\n",
    "idx = idx[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Labrador retriever with 65.0% confidence.\n"
     ]
    }
   ],
   "source": [
    "confidence = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "whatami = labels[idx]\n",
    "me = confidence[idx]\n",
    "print(f\"This is {whatami} with {torch.round(me)}% confidence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2072e+01,  1.1139e+01,  8.8551e+00,  8.1274e+00,  7.7615e+00,\n",
       "           7.3783e+00,  6.9491e+00,  6.4673e+00,  6.3788e+00,  6.2375e+00,\n",
       "           6.2141e+00,  6.1364e+00,  5.9977e+00,  5.7828e+00,  5.7228e+00,\n",
       "           5.6942e+00,  5.6870e+00,  5.6327e+00,  5.4940e+00,  5.4255e+00,\n",
       "           5.4205e+00,  5.4011e+00,  5.3511e+00,  5.2123e+00,  5.1683e+00,\n",
       "           5.1664e+00,  5.1210e+00,  5.0803e+00,  4.9229e+00,  4.8986e+00,\n",
       "           4.8668e+00,  4.8529e+00,  4.7490e+00,  4.7030e+00,  4.6923e+00,\n",
       "           4.6100e+00,  4.5872e+00,  4.5421e+00,  4.5225e+00,  4.4915e+00,\n",
       "           4.4867e+00,  4.4523e+00,  4.4471e+00,  4.4452e+00,  4.4408e+00,\n",
       "           4.4152e+00,  4.4091e+00,  4.3988e+00,  4.3151e+00,  4.1824e+00,\n",
       "           4.1171e+00,  4.0739e+00,  4.0501e+00,  4.0359e+00,  4.0090e+00,\n",
       "           3.9414e+00,  3.9248e+00,  3.9025e+00,  3.7913e+00,  3.7253e+00,\n",
       "           3.7179e+00,  3.7064e+00,  3.7046e+00,  3.6949e+00,  3.6849e+00,\n",
       "           3.6848e+00,  3.6486e+00,  3.6326e+00,  3.6209e+00,  3.5981e+00,\n",
       "           3.5807e+00,  3.5734e+00,  3.5523e+00,  3.5459e+00,  3.5386e+00,\n",
       "           3.4846e+00,  3.4739e+00,  3.4721e+00,  3.4535e+00,  3.4128e+00,\n",
       "           3.4103e+00,  3.3672e+00,  3.3513e+00,  3.2777e+00,  3.2731e+00,\n",
       "           3.1765e+00,  3.1467e+00,  3.1375e+00,  3.1366e+00,  3.1184e+00,\n",
       "           3.1083e+00,  3.0708e+00,  3.0040e+00,  2.9875e+00,  2.9730e+00,\n",
       "           2.9596e+00,  2.9546e+00,  2.9164e+00,  2.9121e+00,  2.9008e+00,\n",
       "           2.9004e+00,  2.8592e+00,  2.8229e+00,  2.8070e+00,  2.7520e+00,\n",
       "           2.7334e+00,  2.6968e+00,  2.6953e+00,  2.6814e+00,  2.6648e+00,\n",
       "           2.6303e+00,  2.5606e+00,  2.5056e+00,  2.4934e+00,  2.4739e+00,\n",
       "           2.4644e+00,  2.4195e+00,  2.4047e+00,  2.3989e+00,  2.3954e+00,\n",
       "           2.3358e+00,  2.3335e+00,  2.2971e+00,  2.2786e+00,  2.2723e+00,\n",
       "           2.2637e+00,  2.2460e+00,  2.2315e+00,  2.1951e+00,  2.1902e+00,\n",
       "           2.1883e+00,  2.1465e+00,  2.1453e+00,  2.1353e+00,  2.1045e+00,\n",
       "           2.1015e+00,  2.0819e+00,  2.0591e+00,  2.0519e+00,  2.0192e+00,\n",
       "           2.0088e+00,  1.9674e+00,  1.9626e+00,  1.9505e+00,  1.9435e+00,\n",
       "           1.9236e+00,  1.9033e+00,  1.8993e+00,  1.8988e+00,  1.8965e+00,\n",
       "           1.8932e+00,  1.8802e+00,  1.8662e+00,  1.8048e+00,  1.7628e+00,\n",
       "           1.7435e+00,  1.7354e+00,  1.7301e+00,  1.6996e+00,  1.6839e+00,\n",
       "           1.6474e+00,  1.6436e+00,  1.6413e+00,  1.6370e+00,  1.6370e+00,\n",
       "           1.6267e+00,  1.6241e+00,  1.6168e+00,  1.6140e+00,  1.5943e+00,\n",
       "           1.5823e+00,  1.5777e+00,  1.5775e+00,  1.5630e+00,  1.5622e+00,\n",
       "           1.5473e+00,  1.5349e+00,  1.5298e+00,  1.5049e+00,  1.4993e+00,\n",
       "           1.4993e+00,  1.4810e+00,  1.4788e+00,  1.4721e+00,  1.4496e+00,\n",
       "           1.4465e+00,  1.4440e+00,  1.4379e+00,  1.4308e+00,  1.4254e+00,\n",
       "           1.4250e+00,  1.4201e+00,  1.4182e+00,  1.3850e+00,  1.3688e+00,\n",
       "           1.3660e+00,  1.3609e+00,  1.3535e+00,  1.3511e+00,  1.3459e+00,\n",
       "           1.3458e+00,  1.3390e+00,  1.3380e+00,  1.3369e+00,  1.3341e+00,\n",
       "           1.3168e+00,  1.3033e+00,  1.2943e+00,  1.2827e+00,  1.2756e+00,\n",
       "           1.2569e+00,  1.2443e+00,  1.2402e+00,  1.2381e+00,  1.2294e+00,\n",
       "           1.2106e+00,  1.2043e+00,  1.1933e+00,  1.1829e+00,  1.1762e+00,\n",
       "           1.1665e+00,  1.1604e+00,  1.1399e+00,  1.1398e+00,  1.1383e+00,\n",
       "           1.1233e+00,  1.1215e+00,  1.1195e+00,  1.1125e+00,  1.0999e+00,\n",
       "           1.0982e+00,  1.0981e+00,  1.0832e+00,  1.0777e+00,  1.0755e+00,\n",
       "           1.0705e+00,  1.0656e+00,  1.0651e+00,  1.0649e+00,  1.0607e+00,\n",
       "           1.0493e+00,  1.0472e+00,  1.0464e+00,  1.0394e+00,  1.0346e+00,\n",
       "           1.0288e+00,  1.0254e+00,  1.0212e+00,  1.0086e+00,  1.0052e+00,\n",
       "           9.9737e-01,  9.6709e-01,  9.4961e-01,  9.4187e-01,  9.4066e-01,\n",
       "           9.3304e-01,  9.2760e-01,  9.2642e-01,  9.1907e-01,  9.0471e-01,\n",
       "           9.0072e-01,  8.9187e-01,  8.8662e-01,  8.8618e-01,  8.7794e-01,\n",
       "           8.7373e-01,  8.6198e-01,  8.5924e-01,  8.4937e-01,  8.4363e-01,\n",
       "           8.4169e-01,  8.3787e-01,  8.3729e-01,  8.3359e-01,  8.3125e-01,\n",
       "           8.1158e-01,  8.1131e-01,  8.0826e-01,  8.0420e-01,  8.0054e-01,\n",
       "           7.9994e-01,  7.9911e-01,  7.8235e-01,  7.7086e-01,  7.7064e-01,\n",
       "           7.6675e-01,  7.6086e-01,  7.5752e-01,  7.5644e-01,  7.4714e-01,\n",
       "           7.3859e-01,  7.3442e-01,  7.2541e-01,  7.2135e-01,  7.1559e-01,\n",
       "           7.1265e-01,  7.1082e-01,  7.0873e-01,  7.0777e-01,  7.0407e-01,\n",
       "           6.9845e-01,  6.9802e-01,  6.9451e-01,  6.8339e-01,  6.8025e-01,\n",
       "           6.6908e-01,  6.6428e-01,  6.5297e-01,  6.5138e-01,  6.5033e-01,\n",
       "           6.2314e-01,  6.1342e-01,  6.1217e-01,  6.1115e-01,  6.0903e-01,\n",
       "           6.0238e-01,  5.9936e-01,  5.9804e-01,  5.9554e-01,  5.9524e-01,\n",
       "           5.8487e-01,  5.7575e-01,  5.7499e-01,  5.7291e-01,  5.5098e-01,\n",
       "           5.3309e-01,  5.2253e-01,  5.1585e-01,  5.1475e-01,  5.1115e-01,\n",
       "           5.0422e-01,  5.0118e-01,  5.0097e-01,  4.9991e-01,  4.9851e-01,\n",
       "           4.9665e-01,  4.8552e-01,  4.7176e-01,  4.6725e-01,  4.6644e-01,\n",
       "           4.6115e-01,  4.5810e-01,  4.5799e-01,  4.4980e-01,  4.4909e-01,\n",
       "           4.4635e-01,  4.4203e-01,  4.3974e-01,  4.3700e-01,  4.3456e-01,\n",
       "           4.2867e-01,  4.2455e-01,  4.2197e-01,  4.0872e-01,  4.0689e-01,\n",
       "           4.0345e-01,  4.0318e-01,  4.0014e-01,  3.9782e-01,  3.9237e-01,\n",
       "           3.9086e-01,  3.8743e-01,  3.7878e-01,  3.7348e-01,  3.6258e-01,\n",
       "           3.6125e-01,  3.5833e-01,  3.5790e-01,  3.5538e-01,  3.4907e-01,\n",
       "           3.3453e-01,  3.3345e-01,  3.2907e-01,  3.2743e-01,  3.2512e-01,\n",
       "           3.2165e-01,  3.1326e-01,  3.0496e-01,  3.0393e-01,  2.8294e-01,\n",
       "           2.8054e-01,  2.7549e-01,  2.7127e-01,  2.4965e-01,  2.4689e-01,\n",
       "           2.4686e-01,  2.4533e-01,  2.3276e-01,  2.3066e-01,  2.2134e-01,\n",
       "           2.1960e-01,  2.1771e-01,  2.1737e-01,  2.1037e-01,  2.0792e-01,\n",
       "           2.0588e-01,  1.9601e-01,  1.9533e-01,  1.8900e-01,  1.8844e-01,\n",
       "           1.8484e-01,  1.7860e-01,  1.7293e-01,  1.6968e-01,  1.6481e-01,\n",
       "           1.6471e-01,  1.5912e-01,  1.5711e-01,  1.4595e-01,  1.4196e-01,\n",
       "           1.2447e-01,  1.2086e-01,  1.1416e-01,  1.0757e-01,  1.0400e-01,\n",
       "           1.0360e-01,  8.7843e-02,  8.6721e-02,  7.4611e-02,  7.2946e-02,\n",
       "           6.8716e-02,  6.7681e-02,  6.6626e-02,  6.6030e-02,  5.3666e-02,\n",
       "           4.9533e-02,  4.5719e-02,  4.1154e-02,  3.6310e-02,  3.5175e-02,\n",
       "           3.1646e-02,  2.6695e-02,  2.4877e-02,  2.4466e-02,  2.3432e-02,\n",
       "           1.9318e-02,  1.4249e-02,  1.3835e-02,  1.1974e-02,  1.0619e-02,\n",
       "           8.1441e-03,  4.5516e-03, -3.9078e-03, -1.6696e-02, -4.6301e-02,\n",
       "          -4.6897e-02, -6.4524e-02, -7.1997e-02, -7.3346e-02, -7.4577e-02,\n",
       "          -7.7218e-02, -8.3558e-02, -8.3691e-02, -9.8780e-02, -9.8978e-02,\n",
       "          -1.0538e-01, -1.0550e-01, -1.0870e-01, -1.0882e-01, -1.0943e-01,\n",
       "          -1.0945e-01, -1.0963e-01, -1.0978e-01, -1.1363e-01, -1.1607e-01,\n",
       "          -1.1937e-01, -1.2100e-01, -1.2849e-01, -1.3377e-01, -1.4432e-01,\n",
       "          -1.5549e-01, -1.5820e-01, -1.6244e-01, -1.7820e-01, -1.8015e-01,\n",
       "          -1.8395e-01, -1.8429e-01, -1.9705e-01, -1.9970e-01, -2.0733e-01,\n",
       "          -2.0976e-01, -2.1922e-01, -2.2791e-01, -2.4767e-01, -2.5294e-01,\n",
       "          -2.5709e-01, -2.6263e-01, -2.6336e-01, -2.6656e-01, -2.7691e-01,\n",
       "          -2.8147e-01, -2.8427e-01, -2.8682e-01, -2.8702e-01, -2.9030e-01,\n",
       "          -3.0013e-01, -3.0108e-01, -3.0964e-01, -3.1041e-01, -3.1071e-01,\n",
       "          -3.1080e-01, -3.1438e-01, -3.1857e-01, -3.2099e-01, -3.2187e-01,\n",
       "          -3.3116e-01, -3.3315e-01, -3.3867e-01, -3.4379e-01, -3.5423e-01,\n",
       "          -3.5472e-01, -3.5473e-01, -3.5763e-01, -3.6104e-01, -3.6380e-01,\n",
       "          -3.7935e-01, -3.8520e-01, -3.8821e-01, -3.9135e-01, -3.9277e-01,\n",
       "          -3.9306e-01, -3.9697e-01, -3.9967e-01, -4.0613e-01, -4.0959e-01,\n",
       "          -4.1057e-01, -4.1398e-01, -4.1524e-01, -4.1872e-01, -4.3410e-01,\n",
       "          -4.3638e-01, -4.3841e-01, -4.4226e-01, -4.5594e-01, -4.6558e-01,\n",
       "          -4.6928e-01, -4.7115e-01, -4.7147e-01, -4.7400e-01, -4.7994e-01,\n",
       "          -4.8182e-01, -4.8456e-01, -4.8709e-01, -4.8812e-01, -4.8906e-01,\n",
       "          -5.0634e-01, -5.0642e-01, -5.1111e-01, -5.1192e-01, -5.1361e-01,\n",
       "          -5.1663e-01, -5.2107e-01, -5.2382e-01, -5.2504e-01, -5.3054e-01,\n",
       "          -5.4438e-01, -5.4622e-01, -5.5535e-01, -5.6014e-01, -5.6104e-01,\n",
       "          -5.6985e-01, -5.7569e-01, -5.8068e-01, -5.8256e-01, -5.9792e-01,\n",
       "          -6.0742e-01, -6.1080e-01, -6.1744e-01, -6.1959e-01, -6.1997e-01,\n",
       "          -6.2184e-01, -6.3228e-01, -6.3339e-01, -6.3650e-01, -6.3657e-01,\n",
       "          -6.3881e-01, -6.4935e-01, -6.5333e-01, -6.5526e-01, -6.5881e-01,\n",
       "          -6.5979e-01, -6.6170e-01, -6.6301e-01, -6.6474e-01, -6.6582e-01,\n",
       "          -6.6885e-01, -6.7039e-01, -6.7462e-01, -6.8323e-01, -6.8968e-01,\n",
       "          -6.9617e-01, -6.9769e-01, -6.9773e-01, -7.0943e-01, -7.2068e-01,\n",
       "          -7.2544e-01, -7.2548e-01, -7.3135e-01, -7.3585e-01, -7.3604e-01,\n",
       "          -7.3632e-01, -7.3753e-01, -7.3836e-01, -7.3845e-01, -7.5343e-01,\n",
       "          -7.6126e-01, -7.6312e-01, -7.6651e-01, -7.6968e-01, -7.7468e-01,\n",
       "          -7.7664e-01, -7.8099e-01, -7.8133e-01, -7.8256e-01, -7.8281e-01,\n",
       "          -7.8316e-01, -7.8443e-01, -7.8615e-01, -7.8831e-01, -7.9129e-01,\n",
       "          -7.9502e-01, -8.0611e-01, -8.1984e-01, -8.2251e-01, -8.2543e-01,\n",
       "          -8.3052e-01, -8.3605e-01, -8.3835e-01, -8.4098e-01, -8.4167e-01,\n",
       "          -8.4944e-01, -8.5191e-01, -8.5764e-01, -8.6284e-01, -8.6575e-01,\n",
       "          -8.6831e-01, -8.8313e-01, -8.8737e-01, -8.9082e-01, -8.9456e-01,\n",
       "          -9.0410e-01, -9.1293e-01, -9.1838e-01, -9.2153e-01, -9.2269e-01,\n",
       "          -9.2737e-01, -9.2834e-01, -9.3118e-01, -9.3135e-01, -9.3778e-01,\n",
       "          -9.6406e-01, -9.6956e-01, -9.7439e-01, -9.7741e-01, -9.8321e-01,\n",
       "          -9.8959e-01, -1.0009e+00, -1.0219e+00, -1.0222e+00, -1.0360e+00,\n",
       "          -1.0363e+00, -1.0434e+00, -1.0546e+00, -1.0610e+00, -1.0611e+00,\n",
       "          -1.0629e+00, -1.0799e+00, -1.0810e+00, -1.0836e+00, -1.0917e+00,\n",
       "          -1.0962e+00, -1.0994e+00, -1.1019e+00, -1.1040e+00, -1.1053e+00,\n",
       "          -1.1054e+00, -1.1068e+00, -1.1076e+00, -1.1087e+00, -1.1118e+00,\n",
       "          -1.1123e+00, -1.1143e+00, -1.1176e+00, -1.1234e+00, -1.1246e+00,\n",
       "          -1.1371e+00, -1.1413e+00, -1.1451e+00, -1.1465e+00, -1.1498e+00,\n",
       "          -1.1571e+00, -1.1576e+00, -1.1594e+00, -1.1646e+00, -1.1647e+00,\n",
       "          -1.1671e+00, -1.1737e+00, -1.1770e+00, -1.1880e+00, -1.1916e+00,\n",
       "          -1.2169e+00, -1.2218e+00, -1.2242e+00, -1.2261e+00, -1.2316e+00,\n",
       "          -1.2317e+00, -1.2508e+00, -1.2531e+00, -1.2735e+00, -1.2748e+00,\n",
       "          -1.2761e+00, -1.2775e+00, -1.2776e+00, -1.2843e+00, -1.2899e+00,\n",
       "          -1.2909e+00, -1.2943e+00, -1.2945e+00, -1.2954e+00, -1.3001e+00,\n",
       "          -1.3075e+00, -1.3126e+00, -1.3132e+00, -1.3144e+00, -1.3150e+00,\n",
       "          -1.3228e+00, -1.3233e+00, -1.3238e+00, -1.3250e+00, -1.3303e+00,\n",
       "          -1.3325e+00, -1.3329e+00, -1.3383e+00, -1.3473e+00, -1.3589e+00,\n",
       "          -1.3612e+00, -1.3736e+00, -1.3762e+00, -1.3853e+00, -1.3870e+00,\n",
       "          -1.3910e+00, -1.3916e+00, -1.3941e+00, -1.3964e+00, -1.4066e+00,\n",
       "          -1.4074e+00, -1.4125e+00, -1.4156e+00, -1.4224e+00, -1.4247e+00,\n",
       "          -1.4345e+00, -1.4457e+00, -1.4489e+00, -1.4522e+00, -1.4563e+00,\n",
       "          -1.4618e+00, -1.4641e+00, -1.4688e+00, -1.4710e+00, -1.4771e+00,\n",
       "          -1.4789e+00, -1.4826e+00, -1.4872e+00, -1.4970e+00, -1.4991e+00,\n",
       "          -1.5000e+00, -1.5013e+00, -1.5026e+00, -1.5209e+00, -1.5219e+00,\n",
       "          -1.5288e+00, -1.5387e+00, -1.5394e+00, -1.5465e+00, -1.5472e+00,\n",
       "          -1.5569e+00, -1.5578e+00, -1.5713e+00, -1.5740e+00, -1.5803e+00,\n",
       "          -1.5859e+00, -1.5969e+00, -1.5984e+00, -1.6042e+00, -1.6055e+00,\n",
       "          -1.6068e+00, -1.6105e+00, -1.6121e+00, -1.6179e+00, -1.6218e+00,\n",
       "          -1.6279e+00, -1.6289e+00, -1.6382e+00, -1.6384e+00, -1.6403e+00,\n",
       "          -1.6417e+00, -1.6422e+00, -1.6688e+00, -1.6787e+00, -1.6850e+00,\n",
       "          -1.6898e+00, -1.6945e+00, -1.7138e+00, -1.7157e+00, -1.7175e+00,\n",
       "          -1.7181e+00, -1.7253e+00, -1.7261e+00, -1.7271e+00, -1.7426e+00,\n",
       "          -1.7463e+00, -1.7520e+00, -1.7520e+00, -1.7542e+00, -1.7545e+00,\n",
       "          -1.7576e+00, -1.7630e+00, -1.7639e+00, -1.7774e+00, -1.7787e+00,\n",
       "          -1.7823e+00, -1.7868e+00, -1.8062e+00, -1.8141e+00, -1.8141e+00,\n",
       "          -1.8190e+00, -1.8207e+00, -1.8390e+00, -1.8396e+00, -1.8398e+00,\n",
       "          -1.8525e+00, -1.8663e+00, -1.8701e+00, -1.8945e+00, -1.8957e+00,\n",
       "          -1.8977e+00, -1.9006e+00, -1.9109e+00, -1.9138e+00, -1.9145e+00,\n",
       "          -1.9153e+00, -1.9171e+00, -1.9216e+00, -1.9248e+00, -1.9326e+00,\n",
       "          -1.9580e+00, -1.9704e+00, -1.9778e+00, -1.9884e+00, -1.9923e+00,\n",
       "          -1.9940e+00, -1.9941e+00, -2.0036e+00, -2.0086e+00, -2.0149e+00,\n",
       "          -2.0168e+00, -2.0183e+00, -2.0219e+00, -2.0443e+00, -2.0552e+00,\n",
       "          -2.0564e+00, -2.0800e+00, -2.0822e+00, -2.1025e+00, -2.1136e+00,\n",
       "          -2.1142e+00, -2.1153e+00, -2.1205e+00, -2.1432e+00, -2.1438e+00,\n",
       "          -2.1487e+00, -2.1489e+00, -2.1493e+00, -2.1555e+00, -2.1600e+00,\n",
       "          -2.1607e+00, -2.1715e+00, -2.1904e+00, -2.1932e+00, -2.1973e+00,\n",
       "          -2.2001e+00, -2.2029e+00, -2.2107e+00, -2.2264e+00, -2.2266e+00,\n",
       "          -2.2287e+00, -2.2420e+00, -2.2425e+00, -2.2656e+00, -2.2914e+00,\n",
       "          -2.2952e+00, -2.3076e+00, -2.3084e+00, -2.3184e+00, -2.3290e+00,\n",
       "          -2.3302e+00, -2.3359e+00, -2.3417e+00, -2.3446e+00, -2.3528e+00,\n",
       "          -2.3565e+00, -2.3615e+00, -2.3743e+00, -2.3784e+00, -2.3861e+00,\n",
       "          -2.3878e+00, -2.3878e+00, -2.3892e+00, -2.3930e+00, -2.3957e+00,\n",
       "          -2.4020e+00, -2.4050e+00, -2.4072e+00, -2.4076e+00, -2.4093e+00,\n",
       "          -2.4411e+00, -2.4449e+00, -2.4457e+00, -2.4496e+00, -2.4573e+00,\n",
       "          -2.4671e+00, -2.4800e+00, -2.4802e+00, -2.5047e+00, -2.5060e+00,\n",
       "          -2.5137e+00, -2.5335e+00, -2.5365e+00, -2.5565e+00, -2.5577e+00,\n",
       "          -2.5918e+00, -2.5991e+00, -2.6035e+00, -2.6038e+00, -2.6352e+00,\n",
       "          -2.6487e+00, -2.6602e+00, -2.6685e+00, -2.6797e+00, -2.6816e+00,\n",
       "          -2.7062e+00, -2.7075e+00, -2.7317e+00, -2.7495e+00, -2.7511e+00,\n",
       "          -2.7539e+00, -2.7666e+00, -2.7768e+00, -2.7821e+00, -2.7867e+00,\n",
       "          -2.7986e+00, -2.8024e+00, -2.8079e+00, -2.8258e+00, -2.8390e+00,\n",
       "          -2.8416e+00, -2.8707e+00, -2.8790e+00, -2.8927e+00, -2.9075e+00,\n",
       "          -2.9258e+00, -2.9566e+00, -2.9774e+00, -2.9969e+00, -3.0091e+00,\n",
       "          -3.0355e+00, -3.0358e+00, -3.0443e+00, -3.0905e+00, -3.1088e+00,\n",
       "          -3.1230e+00, -3.1337e+00, -3.1471e+00, -3.1498e+00, -3.1809e+00,\n",
       "          -3.1857e+00, -3.1970e+00, -3.2256e+00, -3.2383e+00, -3.2411e+00,\n",
       "          -3.2467e+00, -3.2495e+00, -3.2654e+00, -3.2690e+00, -3.2774e+00,\n",
       "          -3.2979e+00, -3.3008e+00, -3.4035e+00, -3.4925e+00, -3.5332e+00,\n",
       "          -3.6616e+00, -3.7513e+00, -3.9198e+00, -4.0006e+00, -4.0681e+00,\n",
       "          -4.1467e+00, -4.1673e+00, -4.1967e+00, -4.2846e+00, -4.6341e+00]],\n",
       "        grad_fn=<SortBackward>),\n",
       " tensor([[208, 207, 222, 257, 216, 220, 167, 190, 175, 212, 247, 205, 215, 218,\n",
       "          188, 200, 159, 240, 162, 232, 166, 206, 152, 194, 852, 241, 522, 170,\n",
       "          168, 210, 256, 249, 185, 219, 231, 156, 214, 248, 264, 805, 163, 176,\n",
       "          995, 235, 244, 255, 226, 238, 209, 229, 189, 217, 211, 160, 708, 227,\n",
       "          154, 243, 228, 198, 676, 197, 192, 251, 179, 174, 158, 262, 164, 180,\n",
       "          181, 182, 153, 213, 234, 258, 700, 202, 165, 574, 169, 267, 178, 157,\n",
       "          539, 246, 173, 371, 813, 689, 203, 996, 270, 254, 250, 239, 184, 263,\n",
       "          731, 273, 252, 236, 151, 155, 199, 196, 434, 161, 356, 193, 296, 183,\n",
       "          191, 699, 187, 416, 615, 776, 683, 260, 204, 667, 765, 463, 186, 641,\n",
       "          284, 601, 998, 588, 842, 514, 400, 172, 551, 242, 666, 876, 910, 341,\n",
       "          432, 639, 253, 358, 956, 299, 804, 279, 578, 558, 728, 529, 869, 885,\n",
       "          680, 201, 177, 266, 429, 844, 808, 831, 111, 285, 936, 841, 567, 947,\n",
       "          722, 793, 419, 431, 331, 993, 678, 428, 797, 827, 451, 195, 906, 543,\n",
       "          792, 230, 948, 435, 368, 224, 221, 265, 269, 596, 653, 384, 693, 930,\n",
       "          824, 225, 359, 870, 618, 659, 233,  73, 677, 292, 501, 373, 593, 261,\n",
       "          399, 994, 646, 929, 568, 964, 499, 259, 113, 330, 465, 750, 638, 782,\n",
       "          623, 448, 515, 559, 589, 911, 763, 992, 758, 376, 999, 534, 855, 516,\n",
       "          452, 491, 294, 281, 621, 380, 714, 101, 697, 524, 631, 733, 430,  26,\n",
       "          740, 834, 245, 887, 899, 811, 838, 445, 987, 332, 502, 602, 767, 566,\n",
       "          961, 977, 749, 741,  52, 610, 537, 282, 985, 879, 362, 494, 577, 975,\n",
       "          469,  86, 552, 735, 370, 385, 738, 935,  32, 785, 790, 862, 132, 923,\n",
       "          775, 411, 274, 617, 531, 925,  78, 861, 875,  80, 990, 883, 461, 828,\n",
       "           83, 938, 969, 490, 684, 712, 375, 823, 810, 962, 773, 361, 912, 655,\n",
       "          796, 513, 374, 761, 872, 882, 736, 880, 660, 519, 395, 271,  28, 335,\n",
       "          614, 822, 357, 447, 594, 901, 739, 496,  89, 412, 512, 769, 836, 715,\n",
       "          223, 843, 702, 971, 300, 720, 937, 949, 587, 944,  63, 439, 401, 939,\n",
       "          705,   0, 584, 972, 744, 681, 287, 608, 301,  41, 818, 672, 826, 426,\n",
       "          293, 126, 268, 981, 719, 530, 946, 860, 902, 409, 116, 438, 523, 272,\n",
       "           70, 541, 310,  82, 856, 757, 663, 789, 345, 691, 337,  29, 149, 171,\n",
       "          433, 636, 630, 286,  10, 388, 723, 470, 464, 472,  81, 369, 777, 846,\n",
       "          978, 633, 729, 128, 378, 698, 382, 590,  47, 932, 477, 511, 379, 427,\n",
       "          437, 616, 129, 413, 703, 462, 658, 542, 104, 812, 122, 503, 632, 459,\n",
       "          389,  23, 417, 743, 982, 324, 866, 457, 364, 926, 302, 288, 444, 599,\n",
       "          791, 575, 859, 891, 613, 968, 619, 635, 748,  53, 283, 701, 673, 984,\n",
       "          394, 674, 422, 865, 692, 275, 974, 898, 297,  21, 772, 322, 851, 604,\n",
       "          752, 726, 350, 418, 645, 298, 145, 647, 629, 420, 280, 493,  25, 353,\n",
       "          979, 642, 600, 711, 889, 943, 110, 959, 295, 830,  62,   5, 482, 878,\n",
       "          342, 518, 291, 794, 440, 323, 612,  38, 507, 620, 456, 506, 311, 478,\n",
       "          406,  91, 837, 278, 550, 442, 309, 562, 904, 798, 570, 916, 488, 115,\n",
       "          716, 644, 383, 591, 991, 854,  72, 881, 850,  27, 931, 276, 521,  79,\n",
       "          112, 825, 336, 377, 868, 768, 622, 787, 556, 806, 446, 366, 626, 988,\n",
       "          892, 237, 595,  99, 665, 505, 520, 127, 334, 940, 303, 652, 897,  51,\n",
       "          487, 747, 360,  59, 308, 725, 355, 742, 914, 450, 670, 732, 318, 319,\n",
       "           36, 921, 386, 381, 780, 423, 586, 650, 934, 473, 682, 290, 326, 114,\n",
       "           75, 807,  60, 756, 307, 306, 441, 560, 582, 304,  42, 696,  74, 597,\n",
       "          607, 690, 746, 945, 421, 766, 525, 662, 753, 724, 909, 544, 816, 305,\n",
       "          656, 941, 970, 867, 549, 486, 471, 919, 845, 942, 779, 759, 890, 800,\n",
       "          410, 414, 103, 545, 903, 781, 314, 686, 535, 997, 820, 960, 643, 634,\n",
       "           95, 651, 688, 338, 150,  14, 352,  87, 661, 572, 627, 504, 135, 121,\n",
       "          710, 671, 146, 585, 312, 583, 474, 458,  57, 896, 436, 563, 392, 107,\n",
       "          986, 325, 365, 611, 858, 853, 648, 928, 774, 136, 327,  44, 764, 108,\n",
       "          927, 277, 657, 351,  71, 953,  92, 976, 479, 770,  64, 508, 387, 476,\n",
       "          455, 564, 706, 117, 784, 603, 966, 717, 955,  43, 835,  35, 402, 668,\n",
       "          483, 951,  46, 907,  68, 795, 372, 557, 408, 106, 917, 398,  45, 783,\n",
       "          576, 694, 605, 480, 363,  98, 649, 546, 143, 102, 848, 989, 346, 840,\n",
       "          320, 754, 815, 915, 390,  66, 958, 329, 443, 317,  40,   1, 134, 492,\n",
       "          771, 801, 857, 123, 965, 637,  30, 778,   4, 415, 609, 313, 721, 569,\n",
       "          863, 125, 598, 118, 120, 344, 367, 924, 664, 343,  33, 339,  24,  65,\n",
       "          140, 405, 730,  17, 918, 905,  39, 809, 475, 913, 950, 124,  90, 606,\n",
       "          453, 391, 553, 579, 727, 973, 799, 695, 328, 832, 348, 679, 528, 884,\n",
       "           19,  31, 340, 873,  22,  93, 481, 497, 333, 571, 755, 573, 289, 119,\n",
       "          404, 713, 704, 954, 133, 527, 532, 654, 952,   8, 877, 460, 148,  88,\n",
       "          817, 316, 354, 786,  56,  94, 675, 847, 349,  34,  37,  84, 131, 886,\n",
       "           49, 548, 760, 526, 509, 829, 821,  58, 489, 407, 640,  16, 142, 718,\n",
       "           11, 498, 495,  77, 466, 144,  67, 833, 484, 745, 315,  97, 762, 580,\n",
       "          533, 138, 554,  20,  54,  12, 814, 624, 517, 920, 425, 957,  13,   3,\n",
       "          888, 737, 555, 540, 874,  18, 963, 485, 467, 449, 139, 137, 819, 707,\n",
       "          130, 908, 893, 147, 454, 397, 864, 980, 685, 105,  85, 687, 967, 849,\n",
       "          895, 803, 709,   7, 802, 734,  96, 500,  61,   2,  76, 871, 669, 900,\n",
       "          788, 347, 538,  48, 468, 109, 565,  50,  15, 100, 547,  55, 321, 625,\n",
       "          894, 536, 141, 933,   9, 751,  69, 561, 510,   6, 424, 403, 581, 393,\n",
       "          592, 628, 839, 922, 396, 983]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_probs, idx = torch.sort(out, descending=True)\n",
    "print(sorted_probs.shape)\n",
    "sorted_probs, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-afeba43ec549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop5conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtop5labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtop5conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "top5conf = [p for p in sorted_probs[:5]]\n",
    "top5labels = [l for l in labels[[i[0] for i in idx[:5]]]]\n",
    "top5conf, top5labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), \"resnet.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
