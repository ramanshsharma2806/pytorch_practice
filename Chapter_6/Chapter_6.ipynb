{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network cost functions are more complex and capable of approximating arbritrary functions because of their underlying operations of $\\large w * x + b$ passed through an activation function $\\large g(z)$ for all of its neurons in all the layers.\n",
    "\n",
    "What makes using deep neural networks so attractive is that it saves us from worrying too much about the exact function that represents our dataâ€”whether it is quadratic, piecewise polynomial,\n",
    "or something else. With a deep neural network model, we have a universal\n",
    "approximator and a method to estimate its parameters. This approximator can be customized\n",
    "to our needs, in terms of model capacity and its ability to model complicated\n",
    "input/output relationships, just by composing simple building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
