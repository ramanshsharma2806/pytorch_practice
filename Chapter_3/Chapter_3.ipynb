{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "## Playing with PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.ones(3)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(1.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0], data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(data[0]), float(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1] = 4 # mutable\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([4, 5, 6, 7])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0000,  2.0000],\n",
       "        [ 4.0000,  5.6000],\n",
       "        [ 1.3000, 13.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.tensor([[4, 2], [4, 5.6], [1.3, 13]], dtype=torch.float64)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4., dtype=torch.float64), tensor(2., dtype=torch.float64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0, 0], p[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0000, 4.0000, 1.3000], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[:, 0] # all rows, first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7.3921e+01, 2.2177e+02, 9.5463e+01,  ..., 2.4743e+02,\n",
       "          2.3186e+02, 1.8471e+02],\n",
       "         [2.3164e+02, 2.0964e+02, 1.1363e+02,  ..., 1.6777e+02,\n",
       "          2.5122e+02, 2.1377e+02],\n",
       "         [1.0128e+02, 6.6627e+01, 1.5165e+02,  ..., 1.8202e+02,\n",
       "          6.8352e+01, 1.4450e+02],\n",
       "         ...,\n",
       "         [6.0329e+01, 2.1142e+01, 8.7827e+00,  ..., 1.8094e+02,\n",
       "          1.9732e+02, 3.0632e+01],\n",
       "         [1.8619e+02, 9.5423e+01, 1.7304e+02,  ..., 1.9380e+02,\n",
       "          8.8524e+01, 8.2293e+00],\n",
       "         [1.5257e+02, 1.2801e+02, 2.0410e+02,  ..., 2.7497e+01,\n",
       "          1.5911e+02, 8.2361e+01]],\n",
       "\n",
       "        [[2.0595e+02, 8.8456e+01, 1.1269e+02,  ..., 1.8545e-01,\n",
       "          1.5378e+01, 1.0435e+02],\n",
       "         [1.0085e+02, 3.0984e-01, 4.0517e+00,  ..., 3.4565e+01,\n",
       "          8.8854e+01, 2.1198e+02],\n",
       "         [2.0915e+02, 2.2783e+02, 1.4824e+02,  ..., 1.5595e+01,\n",
       "          5.5776e+01, 2.2168e+01],\n",
       "         ...,\n",
       "         [2.1573e+02, 2.1028e+02, 1.3941e+02,  ..., 1.1207e+01,\n",
       "          4.6919e+01, 1.2963e+02],\n",
       "         [2.2306e+02, 7.8776e+01, 2.5407e+02,  ..., 9.6785e+01,\n",
       "          1.7076e+02, 1.4039e+02],\n",
       "         [1.7833e+02, 1.9705e+02, 1.4455e+02,  ..., 1.5612e+02,\n",
       "          1.3208e+02, 1.0155e+02]],\n",
       "\n",
       "        [[1.1402e+02, 1.7115e+02, 7.6986e+01,  ..., 1.0012e+02,\n",
       "          1.3373e+02, 1.2007e+01],\n",
       "         [2.4666e+02, 2.2050e+02, 1.5846e+02,  ..., 1.2682e+02,\n",
       "          5.4983e+01, 2.2206e+02],\n",
       "         [1.5271e+01, 1.3139e+02, 2.2788e+02,  ..., 8.7349e+01,\n",
       "          1.7102e+02, 2.5155e+02],\n",
       "         ...,\n",
       "         [9.6363e+01, 1.4333e+02, 2.1071e+02,  ..., 1.8235e+02,\n",
       "          2.4178e+02, 1.6527e+01],\n",
       "         [9.9878e+01, 2.3913e+02, 3.2679e+01,  ..., 4.4303e+01,\n",
       "          9.1835e+01, 1.9511e+02],\n",
       "         [6.8490e+00, 1.3398e+02, 2.1236e+02,  ..., 1.4792e+02,\n",
       "          2.1529e+02, 1.5936e+02]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example image\n",
    "img = torch.rand(3, 28, 28) * 255 # channels x rows x columns\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 28, 28])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor([0.2126, 0.7152, 0.0722]) \n",
    "batch = torch.rand(2, 3, 28, 28) * 255 # 2 is the number of examples\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([28, 28]), torch.Size([2, 28, 28]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.mean(-3).shape, batch.mean(-3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_un = w.unsqueeze(-1).unsqueeze(-1)\n",
    "w_un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 28, 28]), torch.Size([2, 3, 28, 28]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_weights = w_un * img\n",
    "batch_weights = w_un * batch\n",
    "\n",
    "img_weights.shape, batch_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([28, 28]), torch.Size([2, 28, 28]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray = img_weights.sum(-3)\n",
    "batch_gray = batch_weights.sum(-3)\n",
    "img_gray.shape, batch_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28]) torch.Size([2, 3, 28, 28])\n",
      "torch.Size([28, 28]) torch.Size([2, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trying to plot the images\n",
    "print(img.shape, batch.shape)\n",
    "print(img_gray.shape, batch_gray.shape)\n",
    "\n",
    "img_n = img.resize(28, 28, 3)\n",
    "batch_n = batch.resize(28, 28, 3, 2)\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(img_n)\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(batch_n[..., 0])\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(batch_n[..., 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different dtypes in pytorch\n",
    "\n",
    "torch.int8, torch.int16, torch.int32, torch.int64\n",
    "torch.float, torch.float16, torch.float32, torch.float64\n",
    "torch.bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# TO CHANGE THE DTYPE TWO METHODS ARE THERE\n",
    "print(p.dtype)\n",
    "print(p.int().dtype)\n",
    "print(p.to(torch.int64).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
